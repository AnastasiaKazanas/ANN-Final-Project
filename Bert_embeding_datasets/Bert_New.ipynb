{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "bFKXKDfArPNO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import random\n",
        "import torch\n",
        "import pickle\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# !pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiAvJ6yEr4dR",
        "outputId": "f1dfffb3-857e-481e-9473-80b696ec3188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/saurabhshahane/fake-news-classification?dataset_version_number=77...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92.1M/92.1M [00:01<00:00, 79.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                              title  \\\n",
            "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
            "1           1                                                NaN   \n",
            "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
            "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
            "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
            "\n",
            "                                                text  label  \n",
            "0  No comment is expected from Barack Obama Membe...      1  \n",
            "1     Did they post their votes for Hillary already?      1  \n",
            "2   Now, most of the demonstrators gathered last ...      1  \n",
            "3  A dozen politically active pastors came here f...      0  \n",
            "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n"
          ]
        }
      ],
      "source": [
        "#load data from kaggle\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import kagglehub\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"saurabhshahane/fake-news-classification\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/root/.cache/kagglehub/datasets/saurabhshahane/fake-news-classification/versions/77/WELFake_Dataset.csv\")\n",
        "\n",
        "# Check the first few rows of the dataset\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IrA6-jVsJ5I",
        "outputId": "dac4f639-eb96-4a84-a18d-5e6966832cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            " Unnamed: 0      0\n",
            "title         558\n",
            "text           39\n",
            "label           0\n",
            "dtype: int64\n",
            "\n",
            "Number of rows with missing values: 597\n",
            "\n",
            "Rows with missing values:\n",
            "     Unnamed: 0 title                                               text  \\\n",
            "1             1   NaN     Did they post their votes for Hillary already?   \n",
            "43           43   NaN  True. Hillary needs a distraction and what bet...   \n",
            "162         162   NaN  All eyes on Electoral delegates. The People kn...   \n",
            "185         185   NaN                                               Cool   \n",
            "269         269   NaN  A leading US senator: US Supporting War in Syr...   \n",
            "\n",
            "     label  \n",
            "1        1  \n",
            "43       1  \n",
            "162      1  \n",
            "185      1  \n",
            "269      1  \n"
          ]
        }
      ],
      "source": [
        "#check what's missing in the data\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Check how many rows have missing data\n",
        "rows_with_missing_values = df[df.isnull().any(axis=1)]\n",
        "\n",
        "# Print out the missing values summary and rows with missing data\n",
        "print(\"Missing values per column:\\n\", missing_values)\n",
        "print(\"\\nNumber of rows with missing values:\", rows_with_missing_values.shape[0])\n",
        "\n",
        "# Preview the rows with missing values\n",
        "print(\"\\nRows with missing values:\")\n",
        "print(rows_with_missing_values.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QypO8jkCsXf9",
        "outputId": "f5dddb62-7563-4e60-be4d-96dea91ae707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No comment is expected from Barack Obama Members of the #FYF911 or #FukYoFlag and #BlackLivesMatter movements called for the lynching and hanging of white people and cops. They encouraged others on a radio show Tuesday night to  turn the tide  and kill white people and cops to send a message about the killing of black people in America.One of the F***YoFlag organizers is called  Sunshine.  She has a radio blog show hosted from Texas called,  Sunshine s F***ing Opinion Radio Show. A snapshot of her #FYF911 @LOLatWhiteFear Twitter page at 9:53 p.m. shows that she was urging supporters to  Call now!! #fyf911 tonight we continue to dismantle the illusion of white Below is a SNAPSHOT Twitter Radio Call Invite   #FYF911The radio show aired at 10:00 p.m. eastern standard time.During the show, callers clearly call for  lynching  and  killing  of white people.A 2:39 minute clip from the radio show can be heard here. It was provided to Breitbart Texas by someone who would like to be referred to as  Hannibal.  He has already received death threats as a result of interrupting #FYF911 conference calls.An unidentified black man said  when those mother f**kers are by themselves, that s when when we should start f***ing them up. Like they do us, when a bunch of them ni**ers takin  one of us out, that s how we should roll up.  He said,  Cause we already roll up in gangs anyway. There should be six or seven black mother f**ckers, see that white person, and then lynch their ass. Let s turn the tables. They conspired that if  cops started losing people,  then  there will be a state of emergency. He speculated that one of two things would happen,  a big-ass [R s?????] war,  or  ni**ers, they are going to start backin  up. We are already getting killed out here so what the f**k we got to lose? Sunshine could be heard saying,  Yep, that s true. That s so f**king true. He said,  We need to turn the tables on them. Our kids are getting shot out here. Somebody needs to become a sacrifice on their side.He said,  Everybody ain t down for that s**t, or whatever, but like I say, everybody has a different position of war.  He continued,  Because they don t give a f**k anyway.  He said again,  We might as well utilized them for that s**t and turn the tables on these n**ers. He said, that way  we can start lookin  like we ain t havin  that many casualties, and there can be more causalities on their side instead of ours. They are out their killing black people, black lives don t matter, that s what those mother f**kers   so we got to make it matter to them. Find a mother f**ker that is alone. Snap his ass, and then f***in hang him from a damn tree. Take a picture of it and then send it to the mother f**kers. We  just need one example,  and  then people will start watchin .  This will turn the tables on s**t, he said. He said this will start  a trickle-down effect.  He said that when one white person is hung and then they are just  flat-hanging,  that will start the  trickle-down effect.  He continued,  Black people are good at starting trends. He said that was how  to get the upper-hand. Another black man spoke up saying they needed to kill  cops that are killing us. The first black male said,  That will be the best method right there. Breitbart Texas previously reported how Sunshine was upset when  racist white people  infiltrated and disrupted one of her conference calls. She subsequently released the phone number of one of the infiltrators. The veteran immediately started receiving threatening calls.One of the #F***YoFlag movement supporters allegedly told a veteran who infiltrated their publicly posted conference call,  We are going to rape and gut your pregnant wife, and your f***ing piece of sh*t unborn creature will be hung from a tree. Breitbart Texas previously encountered Sunshine at a Sandra Bland protest at the Waller County Jail in Texas, where she said all white people should be killed. She told journalists and photographers,  You see this nappy-ass hair on my head?   That means I am one of those more militant Negroes.  She said she was at the protest because  these redneck mother-f**kers murdered Sandra Bland because she had nappy hair like me. #FYF911 black radicals say they will be holding the  imperial powers  that are actually responsible for the terrorist attacks on September 11th accountable on that day, as reported by Breitbart Texas. There are several websites and Twitter handles for the movement. Palmetto Star  describes himself as one of the head organizers. He said in a YouTube video that supporters will be burning their symbols of  the illusion of their superiority,  their  false white supremacy,  like the American flag, the British flag, police uniforms, and Ku Klux Klan hoods.Sierra McGrone or  Nocturnus Libertus  posted,  you too can help a young Afrikan clean their a** with the rag of oppression.  She posted two photos, one that appears to be herself, and a photo of a black man, wiping their naked butts with the American flag.For entire story: Breitbart News']\n",
            "5049\n",
            "                                                text  label\n",
            "0  No comment is expected from Barack Obama Membe...      1\n",
            "1     Did they post their votes for Hillary already?      1\n",
            "2   Now, most of the demonstrators gathered last ...      1\n",
            "3  A dozen politically active pastors came here f...      0\n",
            "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1\n",
            "\n",
            " [' ', 'And now a message of peace and unity from one of our neighbors to the South:  We, Mexicans, have to kill Donald J. Trump before he becomes President. He is a threat to every single one of us. There are many Mexican Americans living in the U.S. right now and I m asking them to kill Donald Trump before he becomes President. The one in Mexico who have the means, I m asking you to cross the border and go and kill Donald Trump, and as many of his supporters as possible. Anywhere he goes just try to bomb the place, shoot up the place, do something. B..b but he looked like such a nice boy. Don t call him  illegal he just wanted a better life he s just a victim This punk isn t the only one threatening the life of Trump. Watch this video that exposes the truth about how the media ignores these threats:'] \n",
            " [1, 1]\n",
            "62445\n",
            "738 0 2823 112 72134 62719\n"
          ]
        }
      ],
      "source": [
        "#clean the data of missing values\n",
        "\n",
        "# Ensure that all values in 'text' are strings\n",
        "df['text'] = df['text'].fillna('')  # Fill NaN values with an empty string\n",
        "texts = df['text'].astype(str).tolist()  # Convert to list of strings\n",
        "\n",
        "# # map labels to binary values\n",
        "# df['label'] = df['label'].map({'true': 1, 'false': 0})\n",
        "\n",
        "# Check the first few entries\n",
        "print(texts[:1])\n",
        "\n",
        "print(len(texts[0]))\n",
        "\n",
        "# Split the dataset\n",
        "# train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "#     df['text'], df['label'], test_size=0.2, random_state=42\n",
        "\n",
        "dataset = df[['text', 'label']]\n",
        "print(dataset.head())\n",
        "dataset = shuffle(dataset, random_state=42).reset_index(drop=True)\n",
        "texts = dataset['text'].tolist()\n",
        "labels = dataset['label'].tolist()\n",
        "print('\\n', texts[:2], '\\n', labels[:2])\n",
        "\n",
        "count, sec, thr, you = 0, 0, 0, 0\n",
        "new_dic = []\n",
        "for i, k in enumerate(texts):\n",
        "  if len(k) < 200:\n",
        "    thr += 1\n",
        "    # if len(k) > 100:\n",
        "    #   print(k, labels[i])\n",
        "  if k == ' ':\n",
        "    count += 1\n",
        "\n",
        "  if k[:4] == 'http':\n",
        "    you += 1\n",
        "\n",
        "  if k not in new_dic:\n",
        "    new_dic.append(k)\n",
        "\n",
        "new_data = []\n",
        "for i in texts:\n",
        "  if len(i) > 50 and i not in new_data:\n",
        "    new_data.append(i)\n",
        "\n",
        "print(len(new_data))\n",
        "print(count, sec, thr, you, len(texts), len(new_dic))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8msfX1EtEXY",
        "outputId": "4511225d-01c2-4b4b-f963-78434e905735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,   102,     0,  ...,     0,     0,     0],\n",
            "        [  101,  1998,  2085,  ...,     0,     0,     0],\n",
            "        [  101, 11093,  1010,  ...,  4295,  1012,   102],\n",
            "        ...,\n",
            "        [  101,  1006, 26665,  ...,     0,     0,     0],\n",
            "        [  101,  1037,  2082,  ...,  2005,  7987,   102],\n",
            "        [  101,  2023,  2028,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 0,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
            "72134\n"
          ]
        }
      ],
      "source": [
        ")#tokenize with bert\n",
        "#mattias says to put this into batches (XXX - ?)\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to tokenize the text, adjust the max_length parameter based on data analysis (XXX)\n",
        "def encode_text(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors='tf')\n",
        "\n",
        "# Tokenize the text data\n",
        "#train_encodings = encode_text(texts[:10])\n",
        "texts_encodings = tokenizer(list(texts), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Convert labels to tensors\n",
        "labels = torch.tensor(list(labels))\n",
        "\n",
        "# Check the tokenized data\n",
        "print(texts_encodings)\n",
        "print(len(texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYZn4yebLiDL"
      },
      "outputs": [],
      "source": [
        "# with open(\"temp.pkl\", \"rb\") as fOut:\n",
        "#   lol = pickle.load(fOut)\n",
        "# # print(lol['sentences'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdn8rrRdEQeV",
        "outputId": "cb2ee87e-52d6-4b45-b5de-b5504461310c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72134\n"
          ]
        }
      ],
      "source": [
        "# print(len(lol['sentences']))\n",
        "# # print(len(lol['sentences'].index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdoQKFz_FLVD",
        "outputId": "26a9deda-a9a7-41cd-fd21-8d52589df6d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unnamed: 0                                                60264\n",
            "title         Elon Musk’s Tesla Stock Up $2 Billion Since Jo...\n",
            "text          Although Tesla CEO Elon Musk shocked Silicon V...\n",
            "label                                                         0\n",
            "Name: 60264, dtype: object\n",
            "tensor(0)\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "input_ids = texts_encodings['input_ids'].numpy()\n",
        "attention_mask = texts_encodings['attention_mask'].numpy()\n",
        "labels = np.array(labels)\n",
        "\n",
        "with h5py.File('Dataset_first.h5', 'w') as hf:\n",
        "    hf.create_dataset('input_ids', data=input_ids, compression=\"gzip\")\n",
        "    hf.create_dataset('attention_mask', data=attention_mask, compression=\"gzip\")\n",
        "    hf.create_dataset('labels', data=labels, compression=\"gzip\")\n",
        "    dt = h5py.string_dtype(encoding='utf-8')\n",
        "    hf.create_dataset('texts', data=texts, dtype=dt)\n"
      ],
      "metadata": {
        "id": "Ohh2nfsjtASp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Open the HDF5 file in read mode\n",
        "with h5py.File('Dataset_first.h5', 'r') as hf:\n",
        "    # Load the datasets\n",
        "    input_ids = np.array(hf['input_ids'])\n",
        "    attention_mask = np.array(hf['attention_mask'])\n",
        "    labels = np.array(hf['labels'])\n",
        "\n",
        "# Check the loaded data\n",
        "print(\"Input IDs shape:\", input_ids.shape)\n",
        "print(\"Attention Mask shape:\", attention_mask.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "# Example: Access a single data point\n",
        "print(\"First input_ids:\", input_ids[10])\n",
        "print(\"First attention_mask:\", attention_mask[10])\n",
        "print(\"First label:\", labels[10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_ot0J8y5Bi1",
        "outputId": "68c0862e-4000-4932-c7ab-db0e9d57d3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs shape: (72134, 512)\n",
            "Attention Mask shape: (72134, 512)\n",
            "Labels shape: (72134,)\n",
            "First input_ids: [  101  4419  2739  1996  2047  2259  2335  2988  3041  2023  2733  2008\n",
            "  6521  2371 26608  2044  8398  5496  2032  1997  4487 14540 18232 24228\n",
            "  2138  2002 28667 13901  2370  2013  1996  3425  2533  1055  4812  2046\n",
            "  1996  8398  3049  1055  7208  2000  3607  1012  8398 22416  1037  5164\n",
            "  1997 23862  2012  6521  1010  2040  2052  2101  2175  2006  2000  2360\n",
            "  8398  1055 16360 20026  5685  2075  2001  1996  2087 28284  2724  2002\n",
            "  5281  2004  1037  2270  7947  1010  2429  2000  1996  2335  1012 16360\n",
            "  1012 21510  2638  5380  1010  1040  1011 10250 10128  1012  1010  1056\n",
            " 28394  3064  5958  2008  4905  2236  5076  6521  2085  4282  2129  3060\n",
            "  1011  4841  2514  2044  2002  2001  7283 26608  2011  2343  8398  2058\n",
            "  2010 28667 10383  2140  1999  1996  3607  4812  1012  2006  1037 16110\n",
            "  1999  2089  1010  5380  3615  2000  6521  2004  2200  4795  1010  2077\n",
            "  5815  1010  1045  2228  2002  1055  1037 16939  1010  1998  1045  2228\n",
            "  2008  2002  7078  7164  2008  2009  1055  2010  3105  2000  2562 14302\n",
            "  1999  2037  2173  1012  2000  5076  6521  1010  2129  2515  2009  2514\n",
            "  2000  2022  7944  1004 26608  1029  2085  2017  2113  2129  1996  3060\n",
            "  4841  2017  4487 21338  2229  5051 10985  2514  1010  2016  1056 28394\n",
            "  3064  1012  2000  5076  6521  1010  2129  2515  2009  2514  2000  2022\n",
            "  7944  1004 26608  1029  2085  2017  2113  2129  1996  3060  4841  2017\n",
            "  4487 21338  2229  5051 10985  2514 21510  2638  5380  1006  1030 16360\n",
            " 17848  3170  5880  2015  1007  2244  2321  1010  2418  3406  2029  1996\n",
            "  2280  6458  1010  2585  8359  8235  2135  5838  1024  2009  1055  5793\n",
            "  2008 21510  2638  5380 16424  2317  2111  1012  2008  2052  2191  2014\n",
            "  1037  2304 10514 28139 22911  2923  1012  2009  1005  1055  5793  2008\n",
            " 21510  2638  5380 16424  2317  2111  1012  2008  2052  2191  2014  1037\n",
            "  2304 10514 28139 22911  2923  1012 27263  1012 10474  1012  4012  1013\n",
            " 10751  2099  4160  2290  2581 20348 14194  2585  1037  1012  8359  1010\n",
            "  3781  1012  1006  1030  6458 20464 17007  2063  1007  2244  2385  1010\n",
            "  2418  6673  2863  2064  2022  9200  1010  2021  1999 21510  2638  5380\n",
            "  2553  1010  2009  1055  1037  6841   102     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "First attention_mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "First label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNYOZgON_G4y",
        "outputId": "fb9bfafb-25d6-4c49-ce60-034529ff8d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hash comparison passed. Data is identical.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}