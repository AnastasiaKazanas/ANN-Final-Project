{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnastasiaKazanas/ANN-Final-Project/blob/main/Bert_FCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "change this code to use Bert instead of Bag of words. burt embeddings done in separate file."
      ],
      "metadata": {
        "id": "zEtMqdNw_yHy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "bFKXKDfArPNO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uiAvJ6yEr4dR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa582441-1103-458a-a940-232beb9d272b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/saurabhshahane/fake-news-classification?dataset_version_number=77...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92.1M/92.1M [00:01<00:00, 78.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset preview:\n",
            "   Unnamed: 0                                              title  \\\n",
            "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
            "1           1                                                NaN   \n",
            "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
            "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
            "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
            "\n",
            "                                                text  label  \n",
            "0  No comment is expected from Barack Obama Membe...      1  \n",
            "1     Did they post their votes for Hillary already?      1  \n",
            "2   Now, most of the demonstrators gathered last ...      1  \n",
            "3  A dozen politically active pastors came here f...      0  \n",
            "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
            "\n",
            "Dataset statistics:\n",
            "         Unnamed: 0         label\n",
            "count  72134.000000  72134.000000\n",
            "mean   36066.500000      0.514404\n",
            "std    20823.436496      0.499796\n",
            "min        0.000000      0.000000\n",
            "25%    18033.250000      0.000000\n",
            "50%    36066.500000      1.000000\n",
            "75%    54099.750000      1.000000\n",
            "max    72133.000000      1.000000\n",
            "\n",
            "Missing values per column:\n",
            "Unnamed: 0      0\n",
            "title         558\n",
            "text           39\n",
            "label           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"saurabhshahane/fake-news-classification\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/root/.cache/kagglehub/datasets/saurabhshahane/fake-news-classification/versions/77/WELFake_Dataset.csv\")\n",
        "\n",
        "print(\"Dataset preview:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Check for missing values and drop them\n",
        "df.dropna(subset=['text', 'label'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Import BERT embedding generator\n",
        "from bert_ import BertEmbeddings\n",
        "\n",
        "# Initialize the BERT model\n",
        "bert_model = BertEmbeddings()\n",
        "\n",
        "print(\"Computing BERT embeddings for testing data...\")\n",
        "test_embeddings = np.array([bert_model.get_embeddings(text) for text in test_texts])\n"
      ],
      "metadata": {
        "id": "eRQdv5sq2kZt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "0e603204-dbfd-49b8-8597-5df7e861011f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bert_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-485044dcb084>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Import BERT embedding generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbert_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Initialize the BERT model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bert_'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label']"
      ],
      "metadata": {
        "id": "fQViov-v1gat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8msfX1EtEXY"
      },
      "outputs": [],
      "source": [
        "# Convert embeddings and labels to tensors\n",
        "X_train = torch.tensor(train_embeddings, dtype=torch.float32)\n",
        "X_test = torch.tensor(test_embeddings, dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_labels.values, dtype=torch.long)\n",
        "test_labels = torch.tensor(test_labels.values, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train, train_labels)\n",
        "test_dataset = TensorDataset(X_test, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Neural Network\n",
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "input_dim = train_embeddings.shape[1]\n",
        "hidden_dim = 128\n",
        "output_dim = 2\n",
        "\n",
        "model = TextClassifier(input_dim, hidden_dim, output_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        outputs = model(X_batch)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        y_pred.extend(preds.numpy())\n",
        "        y_true.extend(y_batch.numpy())\n"
      ],
      "metadata": {
        "id": "TH8Ve8fUMkgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['False', 'True']))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['False', 'True'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Display a few predictions\n",
        "print(\"\\nSample Predictions:\")\n",
        "for i, (text, pred, true_label) in enumerate(zip(test_texts[:5], y_pred[:5], test_labels[:5])):\n",
        "    print(f\"\\nSample {i+1}\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Predicted: {'True' if pred else 'False'}, Actual: {'True' if true_label else 'False'}\")"
      ],
      "metadata": {
        "id": "jUgXCN1sz-Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1DdVKJX1LIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}