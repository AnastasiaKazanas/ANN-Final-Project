{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bFKXKDfArPNO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import random\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# !pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiAvJ6yEr4dR",
        "outputId": "2ad93b13-bc64-45f9-c0bc-81dc660b4c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0                                              title  \\\n",
            "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
            "1           1                                                NaN   \n",
            "2           2  UNBELIEVABLE! OBAMAâ€™S ATTORNEY GENERAL SAYS MO...   \n",
            "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
            "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
            "\n",
            "                                                text  label  \n",
            "0  No comment is expected from Barack Obama Membe...      1  \n",
            "1     Did they post their votes for Hillary already?      1  \n",
            "2   Now, most of the demonstrators gathered last ...      1  \n",
            "3  A dozen politically active pastors came here f...      0  \n",
            "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n"
          ]
        }
      ],
      "source": [
        "#load data from kaggle\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import kagglehub\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"saurabhshahane/fake-news-classification\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/root/.cache/kagglehub/datasets/saurabhshahane/fake-news-classification/versions/77/WELFake_Dataset.csv\")\n",
        "\n",
        "# Check the first few rows of the dataset\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IrA6-jVsJ5I",
        "outputId": "428af032-e5b3-4bd5-cd4d-d1ac8f0d03be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values per column:\n",
            " Unnamed: 0      0\n",
            "title         558\n",
            "text           39\n",
            "label           0\n",
            "dtype: int64\n",
            "\n",
            "Number of rows with missing values: 597\n",
            "\n",
            "Rows with missing values:\n",
            "     Unnamed: 0 title                                               text  \\\n",
            "1             1   NaN     Did they post their votes for Hillary already?   \n",
            "43           43   NaN  True. Hillary needs a distraction and what bet...   \n",
            "162         162   NaN  All eyes on Electoral delegates. The People kn...   \n",
            "185         185   NaN                                               Cool   \n",
            "269         269   NaN  A leading US senator: US Supporting War in Syr...   \n",
            "\n",
            "     label  \n",
            "1        1  \n",
            "43       1  \n",
            "162      1  \n",
            "185      1  \n",
            "269      1  \n"
          ]
        }
      ],
      "source": [
        "#check what's missing in the data\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Check how many rows have missing data\n",
        "rows_with_missing_values = df[df.isnull().any(axis=1)]\n",
        "\n",
        "# Print out the missing values summary and rows with missing data\n",
        "print(\"Missing values per column:\\n\", missing_values)\n",
        "print(\"\\nNumber of rows with missing values:\", rows_with_missing_values.shape[0])\n",
        "\n",
        "# Preview the rows with missing values\n",
        "print(\"\\nRows with missing values:\")\n",
        "print(rows_with_missing_values.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qadawtw_2C7h"
      },
      "outputs": [],
      "source": [
        "# Ensure that all values in 'text' are strings\n",
        "processed_df = df.copy()\n",
        "processed_df['text'] = df['text'].fillna('')  # Fill NaN values with an empty string\n",
        "texts = processed_df['text'].astype(str).tolist()  # Convert to list of strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRQdv5sq2kZt"
      },
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.2, random_state=42\n",
        ")\n",
        "train_texts = train_texts[:500]\n",
        "train_labels = train_labels[:500]\n",
        "test_texts = test_texts[:500]\n",
        "test_labels = test_labels[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QypO8jkCsXf9",
        "outputId": "21120df3-9066-4be6-9ec1-69961c8fdb2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['No comment is expected from Barack Obama Members of the #FYF911 or #FukYoFlag and #BlackLivesMatter movements called for the lynching and hanging of white people and cops. They encouraged others on a radio show Tuesday night to  turn the tide  and kill white people and cops to send a message about the killing of black people in America.One of the F***YoFlag organizers is called  Sunshine.  She has a radio blog show hosted from Texas called,  Sunshine s F***ing Opinion Radio Show. A snapshot of her #FYF911 @LOLatWhiteFear Twitter page at 9:53 p.m. shows that she was urging supporters to  Call now!! #fyf911 tonight we continue to dismantle the illusion of white Below is a SNAPSHOT Twitter Radio Call Invite   #FYF911The radio show aired at 10:00 p.m. eastern standard time.During the show, callers clearly call for  lynching  and  killing  of white people.A 2:39 minute clip from the radio show can be heard here. It was provided to Breitbart Texas by someone who would like to be referred to as  Hannibal.  He has already received death threats as a result of interrupting #FYF911 conference calls.An unidentified black man said  when those mother f**kers are by themselves, that s when when we should start f***ing them up. Like they do us, when a bunch of them ni**ers takin  one of us out, that s how we should roll up.  He said,  Cause we already roll up in gangs anyway. There should be six or seven black mother f**ckers, see that white person, and then lynch their ass. Let s turn the tables. They conspired that if  cops started losing people,  then  there will be a state of emergency. He speculated that one of two things would happen,  a big-ass [R s?????] war,  or  ni**ers, they are going to start backin  up. We are already getting killed out here so what the f**k we got to lose? Sunshine could be heard saying,  Yep, that s true. That s so f**king true. He said,  We need to turn the tables on them. Our kids are getting shot out here. Somebody needs to become a sacrifice on their side.He said,  Everybody ain t down for that s**t, or whatever, but like I say, everybody has a different position of war.  He continued,  Because they don t give a f**k anyway.  He said again,  We might as well utilized them for that s**t and turn the tables on these n**ers. He said, that way  we can start lookin  like we ain t havin  that many casualties, and there can be more causalities on their side instead of ours. They are out their killing black people, black lives don t matter, that s what those mother f**kers   so we got to make it matter to them. Find a mother f**ker that is alone. Snap his ass, and then f***in hang him from a damn tree. Take a picture of it and then send it to the mother f**kers. We  just need one example,  and  then people will start watchin .  This will turn the tables on s**t, he said. He said this will start  a trickle-down effect.  He said that when one white person is hung and then they are just  flat-hanging,  that will start the  trickle-down effect.  He continued,  Black people are good at starting trends. He said that was how  to get the upper-hand. Another black man spoke up saying they needed to kill  cops that are killing us. The first black male said,  That will be the best method right there. Breitbart Texas previously reported how Sunshine was upset when  racist white people  infiltrated and disrupted one of her conference calls. She subsequently released the phone number of one of the infiltrators. The veteran immediately started receiving threatening calls.One of the #F***YoFlag movement supporters allegedly told a veteran who infiltrated their publicly posted conference call,  We are going to rape and gut your pregnant wife, and your f***ing piece of sh*t unborn creature will be hung from a tree. Breitbart Texas previously encountered Sunshine at a Sandra Bland protest at the Waller County Jail in Texas, where she said all white people should be killed. She told journalists and photographers,  You see this nappy-ass hair on my head?   That means I am one of those more militant Negroes.  She said she was at the protest because  these redneck mother-f**kers murdered Sandra Bland because she had nappy hair like me. #FYF911 black radicals say they will be holding the  imperial powers  that are actually responsible for the terrorist attacks on September 11th accountable on that day, as reported by Breitbart Texas. There are several websites and Twitter handles for the movement. Palmetto Star  describes himself as one of the head organizers. He said in a YouTube video that supporters will be burning their symbols of  the illusion of their superiority,  their  false white supremacy,  like the American flag, the British flag, police uniforms, and Ku Klux Klan hoods.Sierra McGrone or  Nocturnus Libertus  posted,  you too can help a young Afrikan clean their a** with the rag of oppression.  She posted two photos, one that appears to be herself, and a photo of a black man, wiping their naked butts with the American flag.For entire story: Breitbart News']\n",
            "5049\n"
          ]
        }
      ],
      "source": [
        "# #clean the data of missing values\n",
        "\n",
        "# # Ensure that all values in 'text' are strings\n",
        "# df['text'] = df['text'].fillna('')  # Fill NaN values with an empty string\n",
        "# texts = df['text'].astype(str).tolist()  # Convert to list of strings\n",
        "\n",
        "# # map labels to binary values\n",
        "# df['label'] = df['label'].map({'true': 1, 'false': 0})\n",
        "\n",
        "# # Check the first few entries\n",
        "# print(texts[:1])\n",
        "\n",
        "# print(len(texts[0]))\n",
        "\n",
        "# # Split the dataset\n",
        "# train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "#     df['text'], df['label'], test_size=0.2, random_state=42\n",
        "# )\n",
        "# train_texts = train_texts[:500]\n",
        "# train_labels = train_labels[:500]\n",
        "# test_texts = test_texts[:500]\n",
        "# test_labels = test_labels[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "fQViov-v1gat",
        "outputId": "a3041957-b5ec-48ec-ae65-1f1216ac05eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72129</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72130</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72131</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72132</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72133</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72134 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "72129    0\n",
              "72130    1\n",
              "72131    0\n",
              "72132    0\n",
              "72133    1\n",
              "Name: label, Length: 72134, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8msfX1EtEXY",
        "outputId": "dfebba0d-a5fe-46f4-8c6a-c702c5fbf366"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  2348, 26060,  ...,  2230,  1010,   102],\n",
            "        [  101,  6221,  1046,  ...,  5050,  1996,   102],\n",
            "        [  101,  3675,  6477,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 22072,  3201,  ..., 26157,  7982,   102],\n",
            "        [  101,  2047,  2259,  ..., 19506,  2036,   102],\n",
            "        [  101,  2003,  2205,  ...,  1037, 14044,   102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "#tokenize with bert\n",
        "#mattias says to put this into batches (XXX - ?)\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to tokenize the text, adjust the max_length parameter based on data analysis (XXX)\n",
        "def encode_text(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors='tf')\n",
        "\n",
        "# Tokenize the text data\n",
        "#train_encodings = encode_text(texts[:10])\n",
        "train_encodings = tokenizer(list(train_texts), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "test_encodings = tokenizer(list(test_texts), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Convert labels to tensors\n",
        "train_labels = torch.tensor(list(train_labels))\n",
        "test_labels = torch.tensor(list(test_labels))\n",
        "\n",
        "# Check the tokenized data\n",
        "print(train_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXcf_SkYy-sc"
      },
      "outputs": [],
      "source": [
        "# # Initialize the BERT tokenizer\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# # Function to tokenize the text, adjust the max_length parameter based on data analysis (XXX)\n",
        "# def encode_text(texts, max_length=512):  # Allow customization of max_length\n",
        "#     return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='tf')\n",
        "\n",
        "# # # Determine optimal max_length (e.g., using percentile of token lengths)\n",
        "# # token_lengths = [len(tokenizer.encode(text)) for text in texts]\n",
        "# # max_length = int(np.percentile(token_lengths, 95))  # Adjust percentile as needed\n",
        "\n",
        "# # Tokenize the text data in batches\n",
        "# batch_size = 32  # Adjust as needed\n",
        "# all_encodings = []  # Store all encodings\n",
        "\n",
        "# for i in range(0, len(texts), batch_size):\n",
        "#     batch_texts = texts[i : i + batch_size]\n",
        "#     batch_encodings = encode_text(batch_texts, max_length=512)  # Use determined max_length\n",
        "#     all_encodings.append(batch_encodings)\n",
        "\n",
        "# # Check a sample of the tokenized data\n",
        "# print(all_encodings[0])  # Print the encodings for the first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLpUp36Te3Ls",
        "outputId": "a84c40de-3901-4945-bd16-cb867496a530"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create a custom Dataset class\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}, self.labels[idx]\n",
        "\n",
        "# Prepare datasets and data loaders\n",
        "train_dataset = NewsDataset(train_encodings, train_labels)\n",
        "test_dataset = NewsDataset(test_encodings, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Initialize the model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_training_steps = len(train_loader) * 3  # Assuming 3 epochs\n",
        "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Loss function\n",
        "loss_fn = CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipxp4Oxf1GED",
        "outputId": "f5992d41-22f8-4287-b39d-1c4bdb2c2b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])\n"
          ]
        }
      ],
      "source": [
        "for batch in train_loader:\n",
        "        inputs, labels = batch\n",
        "        break\n",
        "\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "7MEWLFvy0Qe7",
        "outputId": "617df603-903e-4013-922f-275d03ee74a9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'outputs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-535fab114e43>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
          ]
        }
      ],
      "source": [
        "# labels = labels.to(device)\n",
        "# labels.long()\n",
        "\n",
        "# outputs.logits.long()\n",
        "\n",
        "# loss_fn(outputs.logits, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZrsxZh8e_iT",
        "outputId": "2a12a896-05d0-4a52-a5b7-e21d1a3ddc4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Loss: 0.7237411737442017\n",
            "Loss: 0.7529557943344116\n",
            "Loss: 0.6579534411430359\n",
            "Loss: 0.641806960105896\n",
            "Loss: 0.6714503169059753\n",
            "Loss: 0.6407596468925476\n",
            "Loss: 0.5614355802536011\n",
            "Loss: 0.5411689877510071\n",
            "Loss: 0.5184589624404907\n",
            "Loss: 0.47074976563453674\n",
            "Loss: 0.4220966398715973\n",
            "Loss: 0.23700210452079773\n",
            "Loss: 0.3481229245662689\n",
            "Loss: 0.2322738766670227\n",
            "Loss: 0.2756775915622711\n",
            "Loss: 0.5010231733322144\n",
            "Loss: 0.29066649079322815\n",
            "Loss: 0.21964502334594727\n",
            "Loss: 0.3859632909297943\n",
            "Loss: 0.3957614600658417\n",
            "Loss: 0.10431446880102158\n",
            "Loss: 0.16809171438217163\n",
            "Loss: 0.19669045507907867\n",
            "Loss: 0.2198384702205658\n",
            "Loss: 0.2620452642440796\n",
            "Loss: 0.196361243724823\n",
            "Loss: 0.24514080584049225\n",
            "Loss: 0.20585930347442627\n",
            "Loss: 0.2178337126970291\n",
            "Loss: 0.28868746757507324\n",
            "Loss: 0.27670443058013916\n",
            "Loss: 0.20817187428474426\n",
            "Epoch 2\n",
            "Loss: 0.1308790147304535\n",
            "Loss: 0.16942256689071655\n",
            "Loss: 0.023522939532995224\n",
            "Loss: 0.030907373875379562\n",
            "Loss: 0.114836685359478\n",
            "Loss: 0.03168383613228798\n",
            "Loss: 0.10213519632816315\n",
            "Loss: 0.08996561169624329\n",
            "Loss: 0.11946507543325424\n",
            "Loss: 0.2714856266975403\n",
            "Loss: 0.14907997846603394\n",
            "Loss: 0.01753000169992447\n",
            "Loss: 0.025914255529642105\n",
            "Loss: 0.03981538861989975\n",
            "Loss: 0.014992891810834408\n",
            "Loss: 0.03868640214204788\n",
            "Loss: 0.011851046234369278\n",
            "Loss: 0.23610490560531616\n",
            "Loss: 0.06757181137800217\n",
            "Loss: 0.009455310180783272\n",
            "Loss: 0.03020859882235527\n",
            "Loss: 0.0228091049939394\n",
            "Loss: 0.07225937396287918\n",
            "Loss: 0.015629518777132034\n",
            "Loss: 0.25536254048347473\n",
            "Loss: 0.020745037123560905\n",
            "Loss: 0.14156539738178253\n",
            "Loss: 0.011841840110719204\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "\n",
        "for epoch in range(3):  # Train for 3 epochs\n",
        "    print(f\"Epoch {epoch + 1}\")\n",
        "    for batch in train_loader:\n",
        "        inputs, labels = batch\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**inputs)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        print(f\"Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhvVv6LlfAYs"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "predictions, true_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        preds = torch.argmax(outputs.logits, axis=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Generate evaluation metrics\n",
        "print(classification_report(true_labels, predictions, target_names=['False', 'True']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nnyYFYbfDmc"
      },
      "outputs": [],
      "source": [
        "#save the model\n",
        "model.save_pretrained('./fake_news_model')\n",
        "tokenizer.save_pretrained('./fake_news_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5EaRsZxrDyv"
      },
      "outputs": [],
      "source": [
        "#tokenize with bert\n",
        "#mattias says to put this into batches (XXX - ?)\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to tokenize the text, adjust the max_length parameter based on data analysis (XXX)\n",
        "def encode_text(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors='tf')\n",
        "\n",
        "# Tokenize the text data\n",
        "#train_encodings = encode_text(texts[:10])\n",
        "train_encodings = tokenizer(list(train_texts), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "test_encodings = tokenizer(list(test_texts), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Convert labels to tensors\n",
        "train_labels = torch.tensor(list(train_labels))\n",
        "test_labels = torch.tensor(list(test_labels))\n",
        "\n",
        "# Check the tokenized data\n",
        "print(train_encodings)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}